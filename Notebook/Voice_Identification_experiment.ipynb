{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice Identification Experiment 1\n",
    "\n",
    "This is the ipynb file for the Digital Signal Processing Experiment.\n",
    "\n",
    "## Data Preprocessing \n",
    "\n",
    "I choose to use the simple endpoint detection to simplify the classification process. To be more specific, I choose to ignore all the noize data whose absolute value is lower than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    " \n",
    "#filepath = \"\" #添加路径\n",
    "filename = 'ryan71.wav'\n",
    "#filename= os.listdir(filepath) #得到文件夹下的所有文件名称 \n",
    "f = wave.open(filename,'rb')\n",
    "params = f.getparams()\n",
    "nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "strData = f.readframes(nframes)#读取音频，字符串格式\n",
    "waveData = np.fromstring(strData,dtype=np.int16)#将字符串转化为int\n",
    "waveData = waveData*1.0/(max(abs(waveData)))#wave幅值归一化\n",
    "Data = []\n",
    "j = 0\n",
    "for i in range(len(waveData)):\n",
    "    if abs(waveData[i]) > 0.05:\n",
    "        Data.append(waveData[i])\n",
    "        j+=1\n",
    "    \n",
    "# plot the wave\n",
    "time = np.arange(0,j)*(1.0 / framerate)\n",
    "plt.plot(time,Data)\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Single channel wavedata\")\n",
    "plt.grid('on')#标尺，on：有，off:无。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we try to preprocess the wavedata using multiple method.\n",
    "\n",
    "## Enframe, Energy and ZCR\n",
    "\n",
    "In this code, I use only 2 wav file to test the program which contains the voice information of zero and seven. I used function using double gate algorithms to detect the endpoints of voice and counting the Energy and ZCR to find different features of voice information. The figures of different features are shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:29: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an index",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3267a0c897d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mwinfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mFrame0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0mFrame7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mEnergy0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-3267a0c897d3>\u001b[0m in \u001b[0;36mEnframe\u001b[0;34m(wavData, frameSize, overlap)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframeSize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mframeNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwlen\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mframeData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframeNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mhamwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an index"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wave\n",
    "import os\n",
    "import math\n",
    "import scipy.signal as signal\n",
    "\n",
    "def Enframe(wavData, frameSize, overlap):#分帧加窗函数\n",
    "    coeff = 0.97 # 预加重系数\n",
    "    wlen = len(wavData)\n",
    "    step = frameSize - overlap\n",
    "    frameNum = math.ceil(wlen / step)\n",
    "    frameData = np.zeros((frameSize, frameNum))\n",
    "\n",
    "    hamwin = np.hamming(frameSize)\n",
    "\n",
    "    for i in range(frameNum):\n",
    "        singleFrame = wavData[np.arange(i * step, min(i * step + frameSize, wlen))]\n",
    "        singleFrame = np.append(singleFrame[0], singleFrame[:-1] - coeff * singleFrame[1:]) # 预加重\n",
    "        frameData[:len(singleFrame), i] = singleFrame\n",
    "        frameData[:, i] = hamwin * frameData[:, i] # 加窗，汉明窗，可以改\n",
    "\n",
    "    return frameData\n",
    "\n",
    "def wavread(filename):\n",
    "    f = wave.open(filename,'rb')\n",
    "    params = f.getparams()\n",
    "    nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "    strData = f.readframes(nframes)#读取音频，字符串格式\n",
    "    waveData = np.fromstring(strData,dtype=np.int16)#将字符串转化为int\n",
    "    f.close()\n",
    "    waveData = waveData*1.0/(max(abs(waveData)))#wave幅值归一化\n",
    "    waveData = np.reshape(waveData,[nframes,nchannels]).T\n",
    "    return waveData\n",
    "\n",
    "# 计算每一帧的过零率\n",
    "def ZCR(frameData):\n",
    "    frameNum = frameData.shape[1] #获取分帧阵的形态\n",
    "    frameSize = frameData.shape[0]\n",
    "    zcr = np.zeros((frameNum, 1)) #设置一个空的矩阵\n",
    "\n",
    "    for i in range(frameNum):\n",
    "        singleFrame = frameData[:, i] #分别对每一帧内的数据进行操作\n",
    "        temp = singleFrame[:frameSize-1] * singleFrame[1:frameSize] #对相邻的位进行相乘操作\n",
    "        temp = np.sign(temp) #将结果转化为符号\n",
    "        zcr[i] = np.sum(temp<0) #将负数个数求总数\n",
    "    return zcr\n",
    "\n",
    "# 计算每一帧能量\n",
    "def energy(frameData):\n",
    "    frameNum = frameData.shape[1]\n",
    "    ener = np.zeros((frameNum, 1))\n",
    "    for i in range(frameNum):\n",
    "        singleframe = frameData[:, i]\n",
    "        ener[i] = sum(singleframe * singleframe)\n",
    "    return ener\n",
    "\n",
    "#新增的利用双门限法的语音端点检测\n",
    "#增强了识别能力，可以用于多数字的语音信息的断点识别\n",
    "def VAD_advance(energy):\n",
    "    MEAN = np.sum(energy)/len(energy)\n",
    "    High = 0.5*MEAN #语音能量上限\n",
    "    Low = 0.015*MEAN #能量下限\n",
    "    Data1 = [] #存放低位能量数据\n",
    "    Data2 = [] #存放高位能量数据\n",
    "    Endpoint = [] #存放两个节点\n",
    "    Flag = 1 #状态位\n",
    "    Flag2 = 1 #状态位\n",
    "    for i in range(len(energy)):\n",
    "        if energy[i] > Low and Flag == 1: #当能量高于低阈值时\n",
    "            if energy[i-1] < Low: #如果上一帧的能量低于低阈值\n",
    "                Data1.append(i-1) #将此节点记录下来\n",
    "                Flag = 0 #状态位置零\n",
    "        if energy[i] > High and Flag2 == 1: #当能量高于高阈值时\n",
    "            if energy[i-1] < High: #如果上一帧的能量低于高阈值\n",
    "                Data2.append(i-1) #将此节点记录下来\n",
    "                Flag2 = 0 #状态位置零\n",
    "        if energy[i] < Low and Flag == 0: #当能量低于低阈值时\n",
    "            if energy[i-1] > Low: #如果上一帧能量高于低阈值\n",
    "                Data1.append(i) #将此节点记录下来\n",
    "                Flag = 1 #状态位置一\n",
    "        if energy[i] < High and Flag2 == 0: #当能量低于高阈值时\n",
    "            if energy[i-1] > High: #如果上一帧能量高于高阈值\n",
    "                Data2.append(i) #将此节点记录下来\n",
    "                Flag2 = 1 #状态位置于一\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while j < len(Data2)/2:#循环遍历数据点，筛选有效的节点\n",
    "        i = 0\n",
    "        while i < len(Data1)/2:\n",
    "            if Data1[2*i]<=Data2[2*j] and Data1[2*i + 1] >= Data2[2*j + 1]:\n",
    "                Endpoint.append(Data1[2*i])\n",
    "                Endpoint.append(Data1[2*i+1])\n",
    "                break\n",
    "            i += 1\n",
    "        j += 1\n",
    "    counter = 2\n",
    "    temp = 0\n",
    "    i = 2\n",
    "    while i < len(Endpoint) - 2: #消除重复点\n",
    "        if Endpoint[i] != Endpoint[i - 2]:\n",
    "            Endpoint[counter] = Endpoint[i]\n",
    "            counter += 1\n",
    "        i += 1\n",
    "    endpoint = []\n",
    "    if len(Endpoint) == 0:\n",
    "        print(\"No endpoint detected\")\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(counter):\n",
    "            endpoint.append(Endpoint[i])\n",
    "        return endpoint\n",
    "\n",
    "filename7 = \"all.wav\"\n",
    "filename0 = \"ryan71.wav\"\n",
    "data0 = wavread(filename0)\n",
    "data7 = wavread(filename7)\n",
    "nw = 512\n",
    "inc = 128\n",
    "winfunc = signal.hamming(nw)\n",
    "Frame0 = Enframe(data0[0], nw, inc) \n",
    "Frame7 = Enframe(data7[0], nw, inc)\n",
    "Energy0 = energy(Frame0)\n",
    "zcr0 = ZCR(Frame0)\n",
    "Energy7 = energy(Frame7)\n",
    "zcr7 = ZCR(Frame7)\n",
    "print(np.shape(Energy7))\n",
    "time = np.arange(0,nframes)*(1.0 / framerate)\n",
    "endpoint = VAD_advance(Energy0)\n",
    "endpoint2 = VAD_advance(Energy7)\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.grid('on')#标尺，on：有，off:无。\n",
    "plt.plot(data0[0])\n",
    "plt.axvline(endpoint[0]*(512-128), color = 'r')\n",
    "plt.axvline(endpoint[1]*(512-128), color = 'r')\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.subplot(212)\n",
    "plt.plot(data7[0])\n",
    "for i in range(len(endpoint2)):\n",
    "    plt.axvline(endpoint2[i]*(512-128), color = 'r')\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid('on')#标尺，on：有，off:无。\n",
    "plt.figure(2)\n",
    "plt.subplot(211)\n",
    "plt.grid('on')#标尺，on：有，off:无。\n",
    "plt.plot(Frame0[0])\n",
    "plt.axvline(endpoint[0], color = 'r')\n",
    "plt.axvline(endpoint[1], color = 'r')\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.subplot(212)\n",
    "plt.plot(Frame7[0])\n",
    "for i in range(len(endpoint2)):\n",
    "    plt.axvline(endpoint2[i], color = 'r')\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid('on')#标尺，on：有，off:无。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Energy0' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c97af3367e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#标尺，on：有，off:无。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnergy0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Energy0' is not defined"
     ],
     "output_type": "error"
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "plt.figure(3)\n",
    "plt.subplot(211)\n",
    "plt.grid('on')#标尺，on：有，off:无。\n",
    "plt.plot(Energy0)\n",
    "plt.axvline(endpoint[0], color = 'r')\n",
    "plt.axvline(endpoint[1], color = 'r')\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude of Energy\")\n",
    "plt.subplot(212)\n",
    "plt.grid('on')#标尺，on：有，off:无。\n",
    "plt.plot(Energy7)\n",
    "for i in range(len(endpoint2)):\n",
    "    plt.axvline(endpoint2[i], color = 'r')\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude of Energy\")\n",
    "plt.figure(4)\n",
    "plt.subplot(211)\n",
    "plt.grid('on')#标尺，on：有，off:无。\n",
    "plt.plot(zcr0)\n",
    "plt.axvline(endpoint[0], color = 'r')\n",
    "plt.axvline(endpoint[1], color = 'r')\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude of zcr\")\n",
    "plt.grid('on')#标尺，on：有，off:无。\n",
    "plt.subplot(212)\n",
    "plt.grid('on')#标尺，on：有，off:无。\n",
    "plt.plot(zcr7)\n",
    "for i in range(len(endpoint2)):\n",
    "    plt.axvline(endpoint2[i], color = 'r')\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude of zcr\")\n",
    "plt.grid('on')#标尺，on：有，off:无。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions for Classifier\n",
    "\n",
    "The svm classifier is applied in the demo below, and several useful functions are used.\n",
    "\n",
    "\n",
    "### FetchFeatureData(endpoint, feature)\n",
    "This function can fatch all the active voice information from original data array. Original data and its endpoint point array are needed. \n",
    "\n",
    "### ReshapeFeatureData(Data, shape)\n",
    "This function will reshape the active data to the shape that you prefer. Data refers to the active voice data from function `FatchFeatureData()`, and shape refers to the shape you need, the function will return the reshaped array with shape (number_of_active_data, shape_of_single_data).\n",
    "\n",
    "All these functions will be useful to different classifier.\n",
    "\n",
    "### Demo: SVM Classifier\n",
    "The svm classifier, for example, is utilized in this demo, using all these functions above. And I choose to use zcr feature of file `ryan02.wav`, `all.wav` in `./Notebook`, which has already loaded and preprocessed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'endpoint2' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e69f9681411f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msvm\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m '''\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mData1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFetchFeatureData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzcr7\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# fatch zcr data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mData1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshapeFeatureDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reshape data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mData2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFetchFeatureData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzcr0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'endpoint2' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from scipy import interpolate\n",
    "from sklearn import svm\n",
    "\n",
    "def FetchFeatureData(endpoints,features):\n",
    "    '''\n",
    "    This information is utilized to fatch all the effective information from a voice data array\n",
    "    :endpoint: the endpoint array of a certain voice data array\n",
    "    :data: the voice feature information array\n",
    "    '''\n",
    "    print(features.shape)\n",
    "    feature_list = []\n",
    "    segment_num = int(len(endpoints) / 2)\n",
    "    for i in range(segment_num):\n",
    "        start, end = endpoints[2 * i], endpoints[2 * i + 1]\n",
    "        feature_list.append(features[start: end])\n",
    "    return feature_list\n",
    "\n",
    "def ReshapeFeatureDataSet(data, shape):\n",
    "    '''\n",
    "    This function is utilized for reshaping the information of data to the shape that you prefer.\n",
    "    Cubic spline interpolate is utilized in reshaping the array.\n",
    "    '''\n",
    "    data_set = []\n",
    "    for i in range(len(data)):\n",
    "        new_shape = np.linspace(0, len(data[i]), shape)\n",
    "        Data = np.reshape(data[i], len(data[i]))\n",
    "        x = np.linspace(0, len(data[i]), len(data[i]))\n",
    "        f = interpolate.interp1d(x, Data, kind='cubic')\n",
    "        data_set.append(f(new_shape))\n",
    "    return data_set\n",
    "\n",
    "'''\n",
    "svm demo\n",
    "the svm function is import from sklearn.\n",
    "'''\n",
    "Data1 = FetchFeatureData(endpoint2,zcr7)  # fatch zcr data\n",
    "Data1 = ReshapeFeatureDataSet(Data1,10)  # reshape data\n",
    "Data2 = FetchFeatureData(endpoint,zcr0)\n",
    "plt.figure(1)\n",
    "plt.plot(Data2[0])\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude of zcr\")\n",
    "Data2 = ReshapeFeatureDataSet(Data2,10)\n",
    "DataSet = np.concatenate((Data1,Data2),axis = 0)  # concatenate two data arrays\n",
    "print(np.shape(DataSet))\n",
    "y = [0,1,2,3,4,5,6,7,8,9,7]  # classification result of DataSet\n",
    "plt.figure(2)\n",
    "plt.plot(Data2[0])\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude of zcr\")\n",
    "plt.figure(3)\n",
    "plt.plot(DataSet[10])\n",
    "clt = svm.SVC(C=0.8, kernel='rbf', gamma=20, decision_function_shape='ovr')\n",
    "clt.fit(DataSet,y)  # svm classification\n",
    "print(clt.score(DataSet,y))  # svm score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility of Python_Speech_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:128: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:134: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (1103) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88064,)\n",
      "(199, 13)\n",
      "(199, 13)\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from python_speech_features import *\n",
    "import scipy.io.wavfile as wav\n",
    "\n",
    "import numpy as np\n",
    "import wave\n",
    "import os\n",
    "import math\n",
    "import scipy.signal as signal\n",
    "\n",
    "def Enframe(wavData, frameSize, overlap):#分帧加窗函数\n",
    "    coeff = 0.97 # 预加重系数\n",
    "    wlen = len(wavData)\n",
    "    step = frameSize - overlap\n",
    "    frameNum = math.ceil(wlen / step)\n",
    "    frameData = np.zeros((frameSize, frameNum))\n",
    "\n",
    "    hamwin = np.hamming(frameSize)\n",
    "\n",
    "    for i in range(frameNum):\n",
    "        singleFrame = wavData[np.arange(i * step, min(i * step + frameSize, wlen))]\n",
    "        singleFrame = np.append(singleFrame[0], singleFrame[:-1] - coeff * singleFrame[1:]) # 预加重\n",
    "        frameData[:len(singleFrame), i] = singleFrame\n",
    "        frameData[:, i] = hamwin * frameData[:, i] # 加窗，汉明窗，可以改\n",
    "\n",
    "    return frameData\n",
    "\n",
    "def wavread(filename):\n",
    "    f = wave.open(filename,'rb')\n",
    "    params = f.getparams()\n",
    "    nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "    strData = f.readframes(nframes)#读取音频，字符串格式\n",
    "    waveData = np.fromstring(strData,dtype=np.int16)#将字符串转化为int\n",
    "    f.close()\n",
    "    waveData = waveData*1.0/(max(abs(waveData)))#wave幅值归一化\n",
    "    waveData = np.reshape(waveData,[nframes,nchannels]).T\n",
    "    return waveData\n",
    "\n",
    "# 计算每一帧的过零率\n",
    "def ZCR(frameData):\n",
    "    frameNum = frameData.shape[1] #获取分帧阵的形态\n",
    "    frameSize = frameData.shape[0]\n",
    "    zcr = np.zeros((frameNum, 1)) #设置一个空的矩阵\n",
    "\n",
    "    for i in range(frameNum):\n",
    "        singleFrame = frameData[:, i] #分别对每一帧内的数据进行操作\n",
    "        temp = singleFrame[:frameSize-1] * singleFrame[1:frameSize] #对相邻的位进行相乘操作\n",
    "        temp = np.sign(temp) #将结果转化为符号\n",
    "        zcr[i] = np.sum(temp<0) #将负数个数求总数\n",
    "    return zcr\n",
    "\n",
    "# 计算每一帧能量\n",
    "def energy(frameData):\n",
    "    frameNum = frameData.shape[1]\n",
    "    ener = np.zeros((frameNum, 1))\n",
    "    for i in range(frameNum):\n",
    "        singleframe = frameData[:, i]\n",
    "        ener[i] = sum(singleframe * singleframe)\n",
    "    return ener\n",
    "\n",
    "#新增的利用双门限法的语音端点检测\n",
    "#增强了识别能力，可以用于多数字的语音信息的断点识别\n",
    "def VAD_advance(energy):\n",
    "    MEAN = np.sum(energy)/len(energy)\n",
    "    High = 0.5*MEAN #语音能量上限\n",
    "    Low = 0.015*MEAN #能量下限\n",
    "    Data1 = [] #存放低位能量数据\n",
    "    Data2 = [] #存放高位能量数据\n",
    "    Endpoint = [] #存放两个节点\n",
    "    Flag = 1 #状态位\n",
    "    Flag2 = 1 #状态位\n",
    "    for i in range(len(energy)):\n",
    "        if energy[i] > Low and Flag == 1: #当能量高于低阈值时\n",
    "            if energy[i-1] < Low: #如果上一帧的能量低于低阈值\n",
    "                Data1.append(i-1) #将此节点记录下来\n",
    "                Flag = 0 #状态位置零\n",
    "        if energy[i] > High and Flag2 == 1: #当能量高于高阈值时\n",
    "            if energy[i-1] < High: #如果上一帧的能量低于高阈值\n",
    "                Data2.append(i-1) #将此节点记录下来\n",
    "                Flag2 = 0 #状态位置零\n",
    "        if energy[i] < Low and Flag == 0: #当能量低于低阈值时\n",
    "            if energy[i-1] > Low: #如果上一帧能量高于低阈值\n",
    "                Data1.append(i) #将此节点记录下来\n",
    "                Flag = 1 #状态位置一\n",
    "        if energy[i] < High and Flag2 == 0: #当能量低于高阈值时\n",
    "            if energy[i-1] > High: #如果上一帧能量高于高阈值\n",
    "                Data2.append(i) #将此节点记录下来\n",
    "                Flag2 = 1 #状态位置于一\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while j < len(Data2)/2:#循环遍历数据点，筛选有效的节点\n",
    "        i = 0\n",
    "        while i < len(Data1)/2:\n",
    "            if Data1[2*i]<=Data2[2*j] and Data1[2*i + 1] >= Data2[2*j + 1]:\n",
    "                Endpoint.append(Data1[2*i])\n",
    "                Endpoint.append(Data1[2*i+1])\n",
    "                break\n",
    "            i += 1\n",
    "        j += 1\n",
    "    counter = 2\n",
    "    temp = 0\n",
    "    i = 2\n",
    "    while i < len(Endpoint) - 2: #消除重复点\n",
    "        if Endpoint[i] != Endpoint[i - 2]:\n",
    "            Endpoint[counter] = Endpoint[i]\n",
    "            counter += 1\n",
    "        i += 1\n",
    "    endpoint = []\n",
    "    if len(Endpoint) == 0:\n",
    "        print(\"No endpoint detected\")\n",
    "        return 0\n",
    "    else:\n",
    "        for i in range(counter):\n",
    "            endpoint.append(Endpoint[i])\n",
    "        return endpoint\n",
    "\n",
    "#filepat = \"\" #添加路径\n",
    "filename1 = 'ryan71.wav'\n",
    "filename2 = 'ryan02.wav'\n",
    "#filename= os.listdir(filepath) #得到文件夹下的所有文件名称 \n",
    "f = wave.open(filename1,'rb')\n",
    "params = f.getparams()\n",
    "nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "strData = f.readframes(nframes)#读取音频，字符串格式\n",
    "waveData1 = np.fromstring(strData,dtype=np.int16)#将字符串转化为int\n",
    "waveData1 = waveData1*1.0/(max(abs(waveData1)))#wave幅值归一化\n",
    "f = wave.open(filename2,'rb')\n",
    "params = f.getparams()\n",
    "nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "strData = f.readframes(nframes)#读取音频，字符串格式\n",
    "waveData2 = np.fromstring(strData,dtype=np.int16)#将字符串转化为int\n",
    "waveData2 = waveData2*1.0/(max(abs(waveData2)))#wave幅值归一化\n",
    "mfcc_feat1 = mfcc(waveData1,44100)\n",
    "mfcc_feat2 = mfcc(waveData2,44100)\n",
    "print(np.shape(waveData1))\n",
    "print(np.shape(mfcc_feat1))\n",
    "print(np.shape(mfcc_feat2))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.51883898181296\n",
      "[[25.76759838 36.60598059 41.24000017 ... 27.27126945 26.22407081\n",
      "  22.72958207]\n",
      " [35.52416595 37.86058125 33.52501833 ... 22.77441481 20.87882178\n",
      "  36.64701266]\n",
      " [46.33389521 47.85509465 42.10170048 ... 34.97057882 33.97232958\n",
      "  39.57201845]\n",
      " ...\n",
      " [41.12660653 33.17285414 34.70069854 ... 29.62106224 30.59513256\n",
      "  36.39331265]\n",
      " [36.80805336 45.78635881 51.78166296 ... 37.0945359  36.83708072\n",
      "  17.4318828 ]\n",
      " [37.42822912 34.89806525 36.71145299 ... 29.34041656 26.65433482\n",
      "  28.7870835 ]]\n",
      "[[   25.76759838    62.37357897   103.61357914 ...  7884.72151819\n",
      "   7910.945589    7933.67517107]\n",
      " [   61.29176433    63.62817964    95.8985973  ...  7880.22466355\n",
      "   7901.10348533  7937.75049799]\n",
      " [  107.62565954   109.14685899   105.72988012 ...  7661.91677403\n",
      "   7695.8891036   7735.46112206]\n",
      " ...\n",
      " [11369.05701766 10693.56897778 10614.51272044 ...  8906.32457486\n",
      "   8936.91970742  8973.31302007]\n",
      " [11405.86507103 10739.35533659 10666.2943834  ...  8913.79804853\n",
      "   8943.16165558  8954.35159022]\n",
      " [11443.29330014 10774.25340184 10703.00583639 ...  8907.05649644\n",
      "   8933.71083127  8962.49791476]]\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 156, 156, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
      "       166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 177,\n",
      "       177, 177, 177, 177, 177, 178, 179, 179, 180, 180, 180, 180, 180,\n",
      "       181, 182, 183, 184, 184, 185, 185, 185, 186, 187, 188, 189, 190,\n",
      "       191, 192, 193, 193, 194, 195, 196, 196, 197, 198, 198, 198, 198,\n",
      "       198, 198]), array([  0,   1,   2,   2,   2,   3,   4,   5,   6,   6,   7,   8,   9,\n",
      "        10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,\n",
      "        23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
      "        36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,\n",
      "        49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
      "        62,  63,  64,  65,  66,  67,  68,  69,  69,  69,  70,  71,  72,\n",
      "        73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  82,  83,  83,\n",
      "        84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
      "        97,  98,  99, 100, 101, 101, 101, 101, 101, 101, 101, 101, 101,\n",
      "       101, 101, 101, 101, 101, 101, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 148, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
      "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "       197, 198]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f76e57e9b90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from numpy import *\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    " \n",
    "def dtw(x, y):\n",
    "    \"\"\"\n",
    "    Computes Dynamic Time Warping (DTW) of two sequences.\n",
    "    :param array x: N1*M array\n",
    "    :param array y: N2*M array\n",
    "    :param func dist: distance used as cost measure\n",
    "    Returns the minimum distance, the cost matrix, the accumulated cost matrix, and the wrap path.\n",
    "    \"\"\"\n",
    "    assert len(x)\n",
    "    assert len(y)\n",
    "    r, c = len(x), len(y)\n",
    "    D0 = zeros((r + 1, c + 1))\n",
    "    D0[0, 1:] = inf\n",
    "    D0[1:, 0] = inf\n",
    "    D1 = D0[1:, 1:] # view\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            D1[i, j] = linalg.norm(x[i] - y[j])\n",
    "    C = D1.copy()\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            D1[i, j] += min(D0[i, j], D0[i, j+1], D0[i+1, j])\n",
    "    if len(x)==1:\n",
    "        path = zeros(len(y)), range(len(y))\n",
    "    elif len(y) == 1:\n",
    "        path = range(len(x)), zeros(len(x))\n",
    "    else:\n",
    "        path = _traceback(D0)\n",
    "    return D1[-1, -1] / sum(D1.shape), C, D1, path\n",
    "\n",
    "def _traceback(D):\n",
    "    i, j = array(D.shape) - 2\n",
    "    p, q = [i], [j]\n",
    "    while ((i > 0) or (j > 0)):\n",
    "        tb = argmin((D[i, j], D[i, j+1], D[i+1, j]))\n",
    "        if (tb == 0):\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif (tb == 1):\n",
    "            i -= 1\n",
    "        else: # (tb == 2):\n",
    "            j -= 1\n",
    "        p.insert(0, i)\n",
    "        q.insert(0, j)\n",
    "    return array(p), array(q)\n",
    "\n",
    "\n",
    "\n",
    "a,b,c,d = dtw(mfcc_feat1,mfcc_feat2)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "plt.imshow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
